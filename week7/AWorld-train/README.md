<div align="center">

# AWorld Train

*é¢å‘ Agentic AI çš„"ä»å®è·µä¸­å­¦ä¹ "è®­ç»ƒæ¡†æ¶*

[![License: MIT][license-image]][license-url]
[![Paper](https://img.shields.io/badge/arXiv-2508.20404-b31b1b.svg)](https://arxiv.org/abs/2508.20404)

</div>

---

## ç›®å½•

- [ç®€ä»‹](#ç®€ä»‹)
  - [å…³äºæœ¬æ•™è‚²æ€§å®éªŒçš„é‡è¦è¯´æ˜](#å…³äºæœ¬æ•™è‚²æ€§å®éªŒçš„é‡è¦è¯´æ˜)
  - [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
- [GAIA ç¯å¢ƒå·¥å…·ç”Ÿæ€](#gaia-ç¯å¢ƒå·¥å…·ç”Ÿæ€)
  - [Web äº¤äº’å·¥å…·](#-web-äº¤äº’å·¥å…·3-æœåŠ¡å™¨9-å·¥å…·)
  - [æ–‡æ¡£å¤„ç†å·¥å…·](#-æ–‡æ¡£å¤„ç†å·¥å…·5-æœåŠ¡å™¨12-å·¥å…·)
  - [å¤šåª’ä½“å¤„ç†å·¥å…·](#-å¤šåª’ä½“å¤„ç†å·¥å…·3-æœåŠ¡å™¨12-å·¥å…·)
  - [æ™ºèƒ½æ¨ç†å·¥å…·](#-æ™ºèƒ½æ¨ç†å·¥å…·3-æœåŠ¡å™¨6-å·¥å…·)
  - [ä»£ç æ‰§è¡Œå·¥å…·](#-ä»£ç æ‰§è¡Œå·¥å…·3-æœåŠ¡å™¨24-å·¥å…·)
  - [æ–‡ä»¶ç³»ç»Ÿå·¥å…·](#-æ–‡ä»¶ç³»ç»Ÿå·¥å…·1-æœåŠ¡å™¨14-å·¥å…·)
  - [Excel å¤„ç†å·¥å…·](#-excel-å¤„ç†å·¥å…·1-æœåŠ¡å™¨29-å·¥å…·)
  - [çŸ¥è¯†æ£€ç´¢å·¥å…·](#-çŸ¥è¯†æ£€ç´¢å·¥å…·3-æœåŠ¡å™¨11-å·¥å…·)
  - [å·¥å…·ç»Ÿè®¡æ€»ç»“](#å·¥å…·ç»Ÿè®¡æ€»ç»“)
- [æ ¸å¿ƒæ¶æ„](#æ ¸å¿ƒæ¶æ„)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
  - [å®‰è£…è®­ç»ƒæ¡†æ¶](#å®‰è£…è®­ç»ƒæ¡†æ¶)
  - [é…ç½® GAIA ç¯å¢ƒ](#é…ç½®-gaia-ç¯å¢ƒ)
- [æ„å»ºè‡ªå®šä¹‰ Agent](#æ„å»ºè‡ªå®šä¹‰-agent)
- [å‡†å¤‡è®­ç»ƒ](#å‡†å¤‡è®­ç»ƒ)
- [å¯åŠ¨è®­ç»ƒ](#å¯åŠ¨è®­ç»ƒ)
- [æœ€æ–°ä¼˜åŒ–](#æœ€æ–°ä¼˜åŒ–)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
- [æ€§èƒ½åŸºå‡†](#æ€§èƒ½åŸºå‡†)
- [è¿›é˜¶ä¸»é¢˜](#è¿›é˜¶ä¸»é¢˜)
- [å¼•ç”¨](#å¼•ç”¨)
- [ç¤¾åŒºä¸æ”¯æŒ](#ç¤¾åŒºä¸æ”¯æŒ)

---

## ç®€ä»‹

AWorld Train æ˜¯å®ç° **"ä»å®è·µä¸­å­¦ä¹ "ï¼ˆLearning from Practiceï¼‰** èŒƒå¼çš„å¼€æºè®­ç»ƒæ¡†æ¶ï¼Œä¸“é—¨ä¸º Agentic AI è®¾è®¡ã€‚æ ¹æ® [AWorld è®ºæ–‡](https://arxiv.org/abs/2508.20404)ï¼Œæ„å»ºé«˜æ€§èƒ½ Agent ç³»ç»Ÿéœ€è¦ä¸‰ä¸ªæ ¸å¿ƒè¦ç´ ï¼š

1. **ç®—æ³•ï¼ˆAlgorithmï¼‰**ï¼šä½¿ Agent èƒ½å¤Ÿä»ç¯å¢ƒäº¤äº’ä¸­é€‚åº”å’Œæ”¹è¿›çš„å­¦ä¹ æœºåˆ¶
2. **ç¯å¢ƒï¼ˆEnvironmentï¼‰**ï¼šæä¾›ä¸°å¯Œåé¦ˆå’Œå¤šæ ·åŒ–æŒ‘æˆ˜çš„å¤æ‚äº¤äº’åœºæ™¯
3. **å…ˆéªŒï¼ˆPriorsï¼‰**ï¼šå½“å‰å¤§æ¨¡å‹åœ¨æ¨ç†ã€æ•°å­¦ã€è§†è§‰ç­‰é¢†åŸŸçš„åŸºç¡€èƒ½åŠ›

AWorld Train é€šè¿‡åˆ†å¸ƒå¼æ¶æ„è§£å†³äº†ä¼ ç»Ÿæ–¹æ³•çš„æ ¸å¿ƒç“¶é¢ˆâ€”â€”**ç»éªŒç”Ÿæˆæ•ˆç‡ä½ä¸‹**ã€‚åœ¨ GAIA åŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬å°†æ•°æ®æ”¶é›†é€Ÿåº¦æå‡äº† **14.6 å€**ï¼Œä½¿å¾—å¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ è®­ç»ƒå˜å¾—å¯è¡Œã€‚

### âš ï¸ å…³äºæœ¬æ•™è‚²æ€§å®éªŒçš„é‡è¦è¯´æ˜

**GAIAï¼ˆGeneral AI Assistants Benchmarkï¼‰** æ˜¯ç›®å‰æœ€å…·æŒ‘æˆ˜æ€§çš„ Agent èƒ½åŠ›è¯„æµ‹åŸºå‡†ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ SOTAï¼ˆState-of-the-Artï¼‰Agent ç³»ç»Ÿçš„ç«æŠ€åœºã€‚æ ¹æ®[è®ºæ–‡](https://arxiv.org/abs/2508.20404)æ‰€ç¤ºï¼š

- **æ•°æ®ç¨€ç¼ºæ€§**ï¼šGAIA validation set ä»…åŒ…å« **165 ä¸ªé—®é¢˜**ï¼Œtest set çº¦ **300 ä¸ªé—®é¢˜**ï¼Œè¿œå°‘äºä¼ ç»Ÿ RL è®­ç»ƒæ‰€éœ€çš„æ•°æ®é‡
- **è®¡ç®—èµ„æºéœ€æ±‚**ï¼šè®ºæ–‡ä¸­çš„ Qwen3-32B-AWorld æ¨¡å‹éœ€è¦åœ¨ 2 å° **8x A100 GPU é›†ç¾¤**ä¸Šè®­ç»ƒå¤šå¤©æ‰èƒ½è¾¾åˆ° 32.23% çš„æ€§èƒ½ï¼Œè€Œè¿™è·ç¦» SOTA æ€§èƒ½ï¼ˆ80% ä»¥ä¸Šï¼‰è¿˜éå¸¸è¿œ
- **ä»»åŠ¡å¤æ‚åº¦**ï¼šGAIA é—®é¢˜æ¶‰åŠå¤šæ¨¡æ€ç†è§£ã€å¤šæ­¥æ¨ç†ã€å·¥å…·é“¾è°ƒç”¨ç­‰ï¼Œå¹³å‡éœ€è¦ 10-20 è½®äº¤äº’æ‰èƒ½å®Œæˆ

å› æ­¤ï¼Œæœ¬é¡¹ç›®é‡‡ç”¨äº†æ•™è‚²å‹å¥½çš„é…ç½®ï¼Œä½¿ç”¨ Qwen3-4B-Thinking-2507 ä½œä¸ºåŸºåº§æ¨¡å‹ï¼Œè®­ç»ƒé€Ÿåº¦è¾ƒå¿«ã€‚

**æœ¬é¡¹ç›®çš„ç›®æ ‡æ˜¯ï¼š**
- âœ… æ¼”ç¤ºå®Œæ•´çš„ "ä»å®è·µä¸­å­¦ä¹ " è®­ç»ƒæµç¨‹
- âœ… ç†è§£ Agent-Environment äº¤äº’æœºåˆ¶
- âœ… å®è·µ RL ç®—æ³•ï¼ˆPPO/GRPOï¼‰åœ¨ Agent è®­ç»ƒä¸­çš„åº”ç”¨

### æ ¸å¿ƒç‰¹æ€§

- âš¡ **é«˜æ•ˆå¹¶å‘**ï¼šåˆ†å¸ƒå¼ä»»åŠ¡æ‰§è¡Œï¼Œ14.6x æ•°æ®æ”¶é›†åŠ é€Ÿ
- ğŸ”Œ **æ¡†æ¶æ— å…³**ï¼šæ”¯æŒ VeRLã€OpenRLHFã€AReaLã€SWIFT ç­‰ä¸»æµ RL æ¡†æ¶
- ğŸ› ï¸ **å·¥å…·ç”Ÿæ€**ï¼šå†…ç½® 26 ä¸ª MCP æœåŠ¡å™¨ï¼Œæä¾› **126 ä¸ªå·¥å…·å‡½æ•°**ï¼Œæ¶µç›–æœç´¢ã€æµè§ˆå™¨ã€ä»£ç æ‰§è¡Œã€å¤šæ¨¡æ€å¤„ç†ç­‰
- ğŸ“Š **é•¿ä¸Šä¸‹æ–‡**ï¼šæ”¯æŒ 131K tokens ä¸Šä¸‹æ–‡ï¼Œå¤„ç†å¤æ‚å¤šè½®äº¤äº’
- ğŸ¯ **SOTA æ€§èƒ½**ï¼šQwen3-32B-AWorld åœ¨ GAIA æµ‹è¯•é›†è¾¾åˆ° 32.23% pass@1

---

## GAIA ç¯å¢ƒå·¥å…·ç”Ÿæ€

æ ¹æ®[è®ºæ–‡](https://arxiv.org/abs/2508.20404)å’Œ MCP Server å®ç°ï¼ŒAWorld ä¸º GAIA ä»»åŠ¡æä¾›äº†å…¨é¢çš„å·¥å…·æ”¯æŒï¼Œå…±è®¡ **26 ä¸ª MCP æœåŠ¡å™¨**ï¼Œ**126 ä¸ªå·¥å…·å‡½æ•°**ã€‚ä»¥ä¸‹æ˜¯æŒ‰ç±»åˆ«çš„å®Œæ•´å·¥å…·åˆ—è¡¨ï¼š

### ğŸŒ Web äº¤äº’å·¥å…·ï¼ˆ3 æœåŠ¡å™¨ï¼Œ9 å·¥å…·ï¼‰

#### 1. Google Search Server (`googlesearch-server`)
- `search_google`: ä½¿ç”¨ Google Custom Search API è¿›è¡Œç½‘ç»œæœç´¢
- `get_search_capabilities`: è·å–æœç´¢æœåŠ¡èƒ½åŠ›ä¿¡æ¯

**å…¸å‹åº”ç”¨**ï¼šæŸ¥è¯¢å®æ—¶ä¿¡æ¯ã€äº‹å®æ ¸æŸ¥ã€å¤šè·³æ¨ç†çš„èµ·ç‚¹

#### 2. Browser Use Server (`browser-server`)
- `browser_use`: åŸºäº LLM çš„æ™ºèƒ½æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆä½¿ç”¨ browser-use åº“ï¼‰
- `get_browser_capabilities`: è·å–æµè§ˆå™¨è‡ªåŠ¨åŒ–èƒ½åŠ›

**ç‰¹æ€§**ï¼š
- è‡ªåŠ¨å¤„ç†æœºå™¨äººæ£€æµ‹å’ŒéªŒè¯ç 
- æ”¯æŒè¡¨å•å¡«å†™ã€æ–‡ä»¶ä¸‹è½½ã€å†…å®¹æå–
- é›†æˆè§†è§‰ç†è§£å’Œè®°å¿†åŠŸèƒ½

#### 3. Playwright Server (`ms-playwright`)
æä¾› **23 ä¸ªç²¾ç»†åŒ–æµè§ˆå™¨æ§åˆ¶å·¥å…·**ï¼š
- **å¯¼èˆª**ï¼š`browser_navigate`, `browser_navigate_back`
- **äº¤äº’**ï¼š`browser_click`, `browser_type`, `browser_hover`, `browser_drag`, `browser_select_option`
- **è¡¨å•**ï¼š`browser_fill_form`, `browser_file_upload`
- **è°ƒè¯•**ï¼š`browser_console_messages`, `browser_network_requests`, `browser_take_screenshot`
- **ç®¡ç†**ï¼š`browser_close`, `browser_resize`, `browser_tabs`, `browser_handle_dialog`
- **æ‰§è¡Œ**ï¼š`browser_evaluate`, `browser_press_key`, `browser_wait_for`
- **å¿«ç…§**ï¼š`browser_snapshot`, `browser_install`

**å¯¹æ¯”**ï¼š`browser-server` æä¾›é«˜çº§è‡ªåŠ¨åŒ–ï¼Œ`ms-playwright` æä¾›ç»†ç²’åº¦æ§åˆ¶

---

### ğŸ“„ æ–‡æ¡£å¤„ç†å·¥å…·ï¼ˆ5 æœåŠ¡å™¨ï¼Œ12 å·¥å…·ï¼‰

#### 4. Documents CSV Server (`documents-csv-server`)
- `extract_csv_content`: æå–å’Œåˆ†æ CSV æ–‡ä»¶å†…å®¹ï¼ˆæ”¯æŒ Markdown/JSON æ ¼å¼è¾“å‡ºï¼‰
- `list_supported_formats`: åˆ—å‡ºæ”¯æŒçš„ CSV æ ¼å¼

#### 5. Documents DOCX Server (`documents-docx-server`)
- `extract_docx_content`: æå– Word æ–‡æ¡£å†…å®¹ï¼ˆåŒ…æ‹¬æ–‡æœ¬ã€è¡¨æ ¼ã€å›¾ç‰‡ï¼‰
- `list_supported_formats`: åˆ—å‡ºæ”¯æŒçš„ DOCX æ ¼å¼

#### 6. Documents PPTX Server (`documents-pptx-server`)
- `extract_pptx_content`: æå– PowerPoint å†…å®¹ï¼ˆå¹»ç¯ç‰‡æ–‡æœ¬ã€æ³¨é‡Šã€å¸ƒå±€ï¼‰
- `list_supported_formats`: åˆ—å‡ºæ”¯æŒçš„ PPTX æ ¼å¼

#### 7. Documents PDF Server (`documents-pdf-server`)
- `convert_document_to_markdown`: å°† PDF è½¬æ¢ä¸º Markdownï¼ˆä¿ç•™ç»“æ„å’Œæ ¼å¼ï¼‰

#### 8. Documents TXT Server (`documents-txt-server`)
- `extract_text_content`: æå–çº¯æ–‡æœ¬æ–‡ä»¶å†…å®¹
- `list_supported_formats`: åˆ—å‡ºæ”¯æŒçš„æ–‡æœ¬ç¼–ç 

**GAIA åº”ç”¨åœºæ™¯**ï¼šå¤„ç†é™„ä»¶æ–‡ä»¶ï¼ˆGAIA æ•°æ®é›† 70% çš„é—®é¢˜åŒ…å«æ–‡æ¡£é™„ä»¶ï¼‰

---

### ğŸ¥ å¤šåª’ä½“å¤„ç†å·¥å…·ï¼ˆ3 æœåŠ¡å™¨ï¼Œ12 å·¥å…·ï¼‰

#### 9. Media Audio Server (`media-audio-server`)
- `transcribe_audio`: è¯­éŸ³è½¬æ–‡å­—ï¼ˆæ”¯æŒ Whisper APIï¼‰
- `extract_audio_metadata`: æå–éŸ³é¢‘å…ƒæ•°æ®ï¼ˆæ—¶é•¿ã€æ¯”ç‰¹ç‡ã€é‡‡æ ·ç‡ï¼‰
- `trim_audio`: è£å‰ªéŸ³é¢‘ç‰‡æ®µ
- `list_supported_formats`: åˆ—å‡ºæ”¯æŒçš„éŸ³é¢‘æ ¼å¼ï¼ˆMP3ã€WAVã€M4A ç­‰ï¼‰

#### 10. Media Image Server (`media-image-server`)
- `extract_text_ocr`: OCR æ–‡å­—è¯†åˆ«ï¼ˆåŸºäº Tesseract/Cloud Vision APIï¼‰
- `analyze_image_ai`: AI å›¾åƒåˆ†æï¼ˆåœºæ™¯è¯†åˆ«ã€å¯¹è±¡æ£€æµ‹ã€æè¿°ç”Ÿæˆï¼‰
- `get_image_metadata`: æå–å›¾åƒå…ƒæ•°æ®ï¼ˆå°ºå¯¸ã€EXIFã€æ‹æ‘„æ—¶é—´ï¼‰

#### 11. Media Video Server (`media-video-server`)
- `analyze_video`: è§†é¢‘å†…å®¹åˆ†æï¼ˆåœºæ™¯åˆ†å‰²ã€å…³é”®å¸§æå–ï¼‰
- `summarize_video`: è§†é¢‘æ‘˜è¦ç”Ÿæˆ
- `extract_keyframes`: æå–å…³é”®å¸§å›¾åƒ

#### è¡¥å……ï¼šç‹¬ç«‹å¤šåª’ä½“å·¥å…·
- **Audio Server** (`audio-server`): `mcp_transcribe_audio` - é«˜çº§è¯­éŸ³è½¬å†™
- **Image Server** (`image-server`): `mcp_image_recognition` - å›¾åƒè¯†åˆ«å’Œåˆ†ç±»

**GAIA åº”ç”¨**ï¼šçº¦ 40% çš„ GAIA é—®é¢˜æ¶‰åŠå›¾ç‰‡ã€éŸ³é¢‘æˆ–è§†é¢‘åˆ†æ

---

### ğŸ’¡ æ™ºèƒ½æ¨ç†å·¥å…·ï¼ˆ3 æœåŠ¡å™¨ï¼Œ6 å·¥å…·ï¼‰

#### 12. Intelligence Code Server (`intelligence-code-server`)
- `generate_python_code`: ç”Ÿæˆå’ŒéªŒè¯ Python ä»£ç ï¼ˆç”¨äºæ•°å­¦è®¡ç®—ã€æ•°æ®å¤„ç†ï¼‰
- `get_reasoning_capabilities`: è·å–ä»£ç ç”Ÿæˆèƒ½åŠ›ä¿¡æ¯

#### 13. Intelligence Think Server (`intelligence-think-server`)
- `complex_problem_reasoning`: å¤æ‚é—®é¢˜æ¨ç†ï¼ˆæ•°å­¦è¯æ˜ã€ç®—æ³•è®¾è®¡ã€é€»è¾‘è°œé¢˜ï¼‰
- `get_reasoning_capabilities`: è·å–æ¨ç†èƒ½åŠ›ä¿¡æ¯

**ç‰¹ç‚¹**ï¼šè°ƒç”¨æ›´å¼ºå¤§çš„æ¨ç†æ¨¡å‹ï¼ˆå¦‚ GPT-4oã€Claude 3.7 Sonnetï¼‰è¿›è¡Œæ·±åº¦æ€è€ƒ

#### 14. Intelligence Guard Server (`intelligence-guard-server`)
- `guarding_reasoning_process`: æ¨ç†è¿‡ç¨‹ä¿æŠ¤å’ŒéªŒè¯ï¼ˆé˜²æ­¢å¹»è§‰ã€æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§ï¼‰
- `get_guarding_capabilities`: è·å–ä¿æŠ¤èƒ½åŠ›ä¿¡æ¯

**è®ºæ–‡äº®ç‚¹**ï¼šè¿™äº›"æ€è€ƒå·¥å…·"ä½¿å°æ¨¡å‹èƒ½å¤Ÿè°ƒç”¨å¤§æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå®ç°"ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Š"

---

### ğŸ’» ä»£ç æ‰§è¡Œå·¥å…·ï¼ˆ3 æœåŠ¡å™¨ï¼Œ24 å·¥å…·ï¼‰

#### 15. Terminal Server (`terminal-server`)
- `execute_command`: æ‰§è¡Œç»ˆç«¯å‘½ä»¤ï¼ˆPythonã€bashã€ç³»ç»Ÿå‘½ä»¤ï¼‰
- `get_command_history`: è·å–å‘½ä»¤æ‰§è¡Œå†å²
- `get_terminal_capabilities`: è·å–ç»ˆç«¯èƒ½åŠ›ä¿¡æ¯

**å®‰å…¨ç‰¹æ€§**ï¼šå‘½ä»¤ç™½åå•ã€è¶…æ—¶æ§åˆ¶ã€è¾“å‡ºæˆªæ–­

#### 16. E2B Code Server (`e2b-code-server`)
- `e2b_upload_file`: ä¸Šä¼ æ–‡ä»¶åˆ°æ²™ç®±
- `e2b_run_code`: åœ¨éš”ç¦»æ²™ç®±ä¸­æ‰§è¡Œä»£ç ï¼ˆæ”¯æŒ Pythonã€JavaScriptã€å¤šç§è¯­è¨€ï¼‰

**ä¼˜åŠ¿**ï¼šå®Œå…¨éš”ç¦»çš„æ‰§è¡Œç¯å¢ƒï¼Œé˜²æ­¢æ¶æ„ä»£ç å½±å“ä¸»ç³»ç»Ÿ

#### 17. Terminal Controller (`terminal-controller`)
æä¾› **10 ä¸ªé«˜çº§ç»ˆç«¯ç®¡ç†å·¥å…·**ï¼š
- `execute_command`, `get_command_history`, `get_current_directory`, `change_directory`
- `list_directory`, `write_file`, `read_file`
- `insert_file_content`, `delete_file_content`, `update_file_content`

**åŒºåˆ«**ï¼š`terminal-server` ä¸“æ³¨å‘½ä»¤æ‰§è¡Œï¼Œ`terminal-controller` æä¾›æ–‡ä»¶ç³»ç»Ÿç®¡ç†

---

### ğŸ“‚ æ–‡ä»¶ç³»ç»Ÿå·¥å…·ï¼ˆ1 æœåŠ¡å™¨ï¼Œ14 å·¥å…·ï¼‰

#### 18. Filesystem Server (`filesystem-server`)
å®Œæ•´çš„æ–‡ä»¶æ“ä½œèƒ½åŠ›ï¼š
- **è¯»å–**ï¼š`read_file`, `read_text_file`, `read_media_file`, `read_multiple_files`
- **å†™å…¥**ï¼š`write_file`, `edit_file`
- **ç®¡ç†**ï¼š`create_directory`, `move_file`, `get_file_info`
- **æœç´¢**ï¼š`search_files`, `list_directory`, `list_directory_with_sizes`, `directory_tree`
- **æƒé™**ï¼š`list_allowed_directories` - åˆ—å‡ºå…è®¸è®¿é—®çš„ç›®å½•

**GAIA åº”ç”¨**ï¼šè®¿é—®æ•°æ®é›†é™„ä»¶ï¼ˆ`/root/workspace/gaia_dataset/` ç›®å½•ï¼‰

---

### ğŸ“Š Excel å¤„ç†å·¥å…·ï¼ˆ1 æœåŠ¡å™¨ï¼Œ29 å·¥å…·ï¼‰

#### 19. Excel Server (`excel`)
æä¾›ä¼ä¸šçº§ Excel æ“ä½œèƒ½åŠ›ï¼š

**æ•°æ®æ“ä½œï¼ˆ9 ä¸ªï¼‰**ï¼š
- `read_data_from_excel`, `write_data_to_excel`
- `insert_rows`, `insert_columns`, `delete_sheet_rows`, `delete_sheet_columns`
- `copy_range`, `delete_range`, `validate_excel_range`

**å·¥ä½œç°¿/è¡¨ç®¡ç†ï¼ˆ7 ä¸ªï¼‰**ï¼š
- `create_workbook`, `create_worksheet`, `copy_worksheet`
- `delete_worksheet`, `rename_worksheet`, `get_workbook_metadata`

**é«˜çº§åŠŸèƒ½ï¼ˆ13 ä¸ªï¼‰**ï¼š
- `apply_formula`, `validate_formula_syntax`
- `format_range`, `create_chart`, `create_pivot_table`, `create_table`
- `merge_cells`, `unmerge_cells`, `get_merged_cells`
- `get_data_validation_info`

**GAIA å…¸å‹ä»»åŠ¡**ï¼šåˆ†æå¤æ‚çš„ Excel æ•°æ®è¡¨ã€è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡ã€ç”Ÿæˆå›¾è¡¨

---

### ğŸ” çŸ¥è¯†æ£€ç´¢å·¥å…·ï¼ˆ3 æœåŠ¡å™¨ï¼Œ11 å·¥å…·ï¼‰

#### 20. Wikipedia Server (`wiki-server`)
- `search_wikipedia`: æœç´¢ç»´åŸºç™¾ç§‘è¯æ¡
- `get_article_content`: è·å–å®Œæ•´æ–‡ç« å†…å®¹
- `get_article_summary`: è·å–æ–‡ç« æ‘˜è¦
- `get_article_categories`: è·å–æ–‡ç« åˆ†ç±»
- `get_article_links`: è·å–æ–‡ç« é“¾æ¥
- `get_article_history`: è·å–æ–‡ç« å†å²ç‰ˆæœ¬ï¼ˆç”¨äºæ—¶é—´æ•æ„Ÿé—®é¢˜ï¼‰
- `get_wikipedia_capabilities`: è·å– Wikipedia æœåŠ¡èƒ½åŠ›

**ç‰¹è‰²åŠŸèƒ½**ï¼šæ”¯æŒå¤šè¯­è¨€ã€å†å²ç‰ˆæœ¬æŸ¥è¯¢ï¼ˆGAIA ä¸­æœ‰"æŸå¹´æŸæœˆçš„äººå£æ•°æ®"ç±»é—®é¢˜ï¼‰

#### 21. ArXiv Server (`parxiv-server`)
- `search_papers`: æœç´¢ arXiv è®ºæ–‡
- `get_paper_details`: è·å–è®ºæ–‡è¯¦ç»†ä¿¡æ¯ï¼ˆæ‘˜è¦ã€ä½œè€…ã€å¼•ç”¨ï¼‰
- `download_paper`: ä¸‹è½½è®ºæ–‡ PDF
- `get_arxiv_capabilities`: è·å– arXiv æœåŠ¡èƒ½åŠ›
- `get_categories`: è·å– arXiv åˆ†ç±»åˆ—è¡¨

#### 22. Wayback Machine Server (`wayback-server`)
- `list_archived_versions`: åˆ—å‡ºç½‘é¡µçš„å†å²å­˜æ¡£ç‰ˆæœ¬
- `get_archived_content`: è·å–ç‰¹å®šæ—¶é—´ç‚¹çš„ç½‘é¡µå†…å®¹
- `get_wayback_capabilities`: è·å– Wayback Machine èƒ½åŠ›

**GAIA åº”ç”¨**ï¼šå›ç­”"2015 å¹´æŸç½‘ç«™ä¸Šçš„ä¿¡æ¯"è¿™ç±»å†å²æŸ¥è¯¢é—®é¢˜

---

### ğŸ“¥ å…¶ä»–å®ç”¨å·¥å…·ï¼ˆ3 æœåŠ¡å™¨ï¼Œ3 å·¥å…·ï¼‰

#### 23. Download Server (`download-server`)
- `download_file`: ä¸‹è½½ç½‘ç»œæ–‡ä»¶åˆ°æœ¬åœ°
- `get_download_capabilities`: è·å–ä¸‹è½½æœåŠ¡èƒ½åŠ›

#### 24. Read Web Server (`readweb-server`)
- æä¾›ç½‘é¡µå†…å®¹è¯»å–èƒ½åŠ›ï¼ˆå…·ä½“å·¥å…·ç”± MCP é…ç½®å®šä¹‰ï¼‰

#### 25. Google Search Alternative (`google-search`)
- `search`: ç®€åŒ–çš„æœç´¢æ¥å£
- `read_webpage`: è¯»å–ç½‘é¡µå†…å®¹

---

### å·¥å…·ç»Ÿè®¡æ€»ç»“

| ç±»åˆ« | æœåŠ¡å™¨æ•° | å·¥å…·æ•° | å…³é”®èƒ½åŠ› |
|------|---------|--------|---------|
| **Web äº¤äº’** | 3 | 32 | æœç´¢ã€æ™ºèƒ½æµè§ˆã€ç²¾ç»†æ§åˆ¶ |
| **æ–‡æ¡£å¤„ç†** | 5 | 12 | CSVã€Wordã€PPTã€PDFã€TXT |
| **å¤šåª’ä½“** | 5 | 14 | éŸ³é¢‘è½¬å†™ã€OCRã€å›¾åƒ/è§†é¢‘åˆ†æ |
| **æ™ºèƒ½æ¨ç†** | 3 | 6 | ä»£ç ç”Ÿæˆã€å¤æ‚æ¨ç†ã€éªŒè¯ |
| **ä»£ç æ‰§è¡Œ** | 3 | 36 | ç»ˆç«¯å‘½ä»¤ã€æ²™ç®±æ‰§è¡Œã€æ–‡ä»¶ç®¡ç† |
| **æ–‡ä»¶ç³»ç»Ÿ** | 1 | 14 | å®Œæ•´æ–‡ä»¶æ“ä½œèƒ½åŠ› |
| **Excel** | 1 | 29 | ä¼ä¸šçº§è¡¨æ ¼å¤„ç† |
| **çŸ¥è¯†æ£€ç´¢** | 3 | 11 | Wikipediaã€ArXivã€å†å²ç½‘é¡µ |
| **å…¶ä»–** | 2 | 3 | æ–‡ä»¶ä¸‹è½½ã€ç½‘é¡µè¯»å– |
| **æ€»è®¡** | **26** | **126** | **æ¶µç›– GAIA æ‰€éœ€çš„å…¨éƒ¨èƒ½åŠ›** |

### å·¥å…·è°ƒç”¨ç¤ºä¾‹ï¼ˆæ¥è‡ªè®­ç»ƒæ—¥å¿—ï¼‰

```python
# Google æœç´¢ç¤ºä¾‹
Tool call: aworld-mcp__search_google
Tool args: {"query": "Wyoming population 2020", "num_results": 5}
Result: {"success": true, "results": [{"title": "Wyoming - Census Bureau", "snippet": "576,851..."}]}

# æ–‡ä»¶ç³»ç»Ÿç¤ºä¾‹
Tool call: aworld-mcp__list_directory
Tool args: {"path": "/root/workspace/gaia_dataset/2023/test"}
Result: ["[FILE] 021a5339-...-bd9b-9368b3efda7a.pdf", "[FILE] 03c577c9-...-f8f598de14c1.mp3", ...]

# CSV å¤„ç†ç¤ºä¾‹ï¼ˆç¼ºå°‘ tabulate ä¾èµ–æ—¶ä¼šæŠ¥é”™ï¼‰
Tool call: aworld-mcp__extract_csv_content
Tool args: {"file_path": "/root/workspace/gaia_dataset/2023/test/52e8ce1c-...-67d1648779b9.csv"}
Error: "CSV extraction failed: Missing optional dependency 'tabulate'"

# Wikipedia å†å²æŸ¥è¯¢ç¤ºä¾‹
Tool call: aworld-mcp__get_article_history
Tool args: {"title": "Cat", "date": "20191231", "language": "en"}
Result: {...historical Wikipedia content...}
```

---

## æ ¸å¿ƒæ¶æ„

AWorld Train é‡‡ç”¨å››é˜¶æ®µè®­ç»ƒæµæ°´çº¿ï¼š

![Architecture](../docs/imgs/train_env_agent_architecture.png)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Environment â”‚â”€â”€â”€â–¶â”‚    Agent    â”‚â”€â”€â”€â–¶â”‚   Adapter   â”‚â”€â”€â”€â–¶â”‚   Training  â”‚
â”‚   Setup     â”‚    â”‚Construction â”‚    â”‚   Layer     â”‚    â”‚  Framework  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     (MCP)           (AWorld)            (VeRL)           (PPO/GRPO)
```

1. **ç¯å¢ƒé…ç½®**ï¼šéƒ¨ç½² GAIA MCP Serverï¼Œæä¾› 20+ å·¥å…·èƒ½åŠ›
2. **Agent æ„å»º**ï¼šå®ç°è‡ªå®šä¹‰ AgentLoopï¼Œå®šä¹‰å†³ç­–é€»è¾‘
3. **é€‚é…å™¨é›†æˆ**ï¼šç»Ÿä¸€æ¥å£ï¼Œå¯¹æ¥ RL è®­ç»ƒæ¡†æ¶
4. **è®­ç»ƒæ‰§è¡Œ**ï¼šé…ç½®å¥–åŠ±å‡½æ•°å’Œè¶…å‚æ•°ï¼Œå¯åŠ¨è®­ç»ƒä»»åŠ¡

---

## å¿«é€Ÿå¼€å§‹

### ç³»ç»Ÿè¦æ±‚

| ç»„ä»¶ | è¦æ±‚ |
|------|------|
| **æ“ä½œç³»ç»Ÿ** | Linux (æ¨è) / macOS / Windows |
| **ç¡¬ä»¶** | æœ€ä½ 4 CPU æ ¸å¿ƒ + 8GB RAM<br>è®­ç»ƒæ¨è 8x A100/H100 GPU |
| **è½¯ä»¶** | Docker, NVIDIA Driver, CUDA 12.1+ |

### å®‰è£…è®­ç»ƒæ¡†æ¶

ä»¥ VeRL ä¸ºä¾‹ï¼Œå®‰è£…æ­¥éª¤å¦‚ä¸‹ï¼š

```bash
# 1. å®‰è£…ç³»ç»Ÿä¾èµ–ï¼ˆUbuntu/Debianï¼‰
sudo apt-get update
sudo apt-get install -y build-essential git wget

# 2. å®‰è£… CUDA Toolkitï¼ˆåŒ¹é…ä½ çš„ GPU Driverï¼‰
# å‚è€ƒï¼šhttps://developer.nvidia.com/cuda-downloads

# 3. å®‰è£… PyTorchï¼ˆåŒ¹é… CUDA ç‰ˆæœ¬ï¼‰
pip install torch==2.4.0 torchvision==0.19.0 --index-url https://download.pytorch.org/whl/cu121

# 4. å…‹éš† AWorld ä»“åº“
git clone https://github.com/inclusionAI/AWorld.git ~/AWorld
cd ~/AWorld

# 5. å®‰è£… VeRL å’Œä¾èµ–ï¼ˆä¼šè‡ªåŠ¨å®‰è£… transformersã€vllmã€deepspeed ç­‰ï¼‰
cd /path/to/verl
pip install -e .
```

**é‡è¦æç¤º**ï¼šVeRL çš„æŸäº›ä¾èµ–éœ€è¦åœ¨ CUDA ç¯å¢ƒä¸‹ç¼–è¯‘ï¼Œè¯·ç¡®ä¿å…ˆå®Œæˆæ­¥éª¤ 1-2ã€‚

---

### é…ç½® GAIA ç¯å¢ƒ

GAIA ç¯å¢ƒé€šè¿‡ Docker éƒ¨ç½²ï¼Œæä¾› MCPï¼ˆModel Context Protocolï¼‰æœåŠ¡ã€‚

#### 1. ä¸‹è½½æ•°æ®é›†

```bash
# ä» Hugging Face ä¸‹è½½ GAIA æ•°æ®é›†
cd ~/AWorld/env/gaia-mcp-server/docker
mkdir -p gaia_dataset

# ä½¿ç”¨ Hugging Face CLI ä¸‹è½½ï¼ˆéœ€è¦å…ˆ pip install huggingface_hubï¼‰
huggingface-cli download gaia-benchmark/GAIA --repo-type dataset --local-dir gaia_dataset
```

#### 2. é…ç½®ç¯å¢ƒå˜é‡

```bash
cd ~/AWorld/env/gaia-mcp-server/mcp_servers
cp .env_template .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œé…ç½®å¿…è¦çš„ API å¯†é’¥
vim .env
```

`.env` æ–‡ä»¶ç¤ºä¾‹ï¼ˆéƒ¨åˆ†å­—æ®µï¼‰ï¼š

```bash
# OpenAI APIï¼ˆç”¨äº intelligence-code-server ç­‰ï¼‰
OPENAI_API_KEY=sk-your-openai-key

# Google Search APIï¼ˆç”¨äº googlesearch-serverï¼‰
GOOGLE_API_KEY=your-google-api-key
GOOGLE_CSE_ID=your-search-engine-id

# E2B APIï¼ˆç”¨äºä»£ç æ‰§è¡Œæ²™ç®±ï¼‰
E2B_API_KEY=your-e2b-api-key
```

#### 3. å¯åŠ¨ MCP Server

```bash
cd ~/AWorld/env
bash run-local.sh
```

å¯åŠ¨æˆåŠŸåï¼Œä½ å°†çœ‹åˆ°ç±»ä¼¼è¾“å‡ºï¼š

```
Starting services...
DISPLAY=:0
2025-10-06 05:20:42,368 - __main__ - INFO - Starting MCP Server Proxy...
2025-10-06 05:20:42,373 - mcp_server_proxy.mcp_server_proxy - INFO - Added MCP server executor: googlesearch-server
...
INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)
```

MCP Server æä¾›ä¸¤ä¸ªæœåŠ¡ï¼š
- **MCP æ¥å£**ï¼š`http://localhost:8080/mcp`ï¼ˆAgent å·¥å…·è°ƒç”¨ï¼‰
- **VNC ç•Œé¢**ï¼š`http://localhost:5901/vnc.html?autoconnect=true`ï¼ˆå¯è§†åŒ–è°ƒè¯•ï¼‰

#### 4. éªŒè¯ç¯å¢ƒ

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export MCP_SERVER_URL=http://localhost:8080/mcp

# æµ‹è¯•è¿æ¥ï¼ˆPythonï¼‰
python3 << EOF
from train.adapter.verl.common import get_agent_tool_env_and_servers

config, servers = get_agent_tool_env_and_servers()
print(f"Available servers: {len(servers)}")
print(f"Sample servers: {servers[:5]}")
EOF
```

é¢„æœŸè¾“å‡ºï¼š

```
Available servers: 20
Sample servers: ['readweb-server', 'browser-server', 'documents-csv-server', ...]
```

---

## æ„å»ºè‡ªå®šä¹‰ Agent

### å®ç° AgentLoop

åˆ›å»ºè‡ªå®šä¹‰ Agent çš„æ ¸å¿ƒæ˜¯ç»§æ‰¿ `AworldAgentLoop` å¹¶å®ç° `build_agents()` æ–¹æ³•ã€‚ä»¥ä¸‹æ˜¯ GAIA Agent çš„å®Œæ•´ç¤ºä¾‹ï¼š

```python
# train/examples/train_gaia_with_aworld_verl/custom_agent_loop.py

from aworld.agents.llm_agent import Agent
from aworld.config import AgentConfig
from train.adapter.verl.aworld_agent_loop import AworldAgentLoop
from train.adapter.verl.common import get_agent_tool_env_and_servers

class GaiaAgentLoop(AworldAgentLoop):
    """GAIA ä»»åŠ¡çš„è‡ªå®šä¹‰ Agent Loop"""
    
    def build_agents(self):
        # è·å– MCP ç¯å¢ƒé…ç½®å’Œå¯ç”¨æœåŠ¡åˆ—è¡¨
        gaia_env_config, gaia_env_servers = get_agent_tool_env_and_servers()
        
        # æ„å»º Agent å®ä¾‹
        return Agent(
            conf=AgentConfig(
                # LLM æœåŠ¡åœ°å€ç”± VeRL åŠ¨æ€ç®¡ç†
                llm_base_url=self.get_llm_server_address(),
                llm_model_name=self.get_llm_server_model_name(),
                llm_api_key="dummy",  # VeRL å†…éƒ¨é€šä¿¡ä¸éœ€è¦çœŸå® API Key
            ),
            name="gaia_super_agent",
            
            # ç³»ç»Ÿæç¤ºï¼ˆå®šä¹‰ Agent è§’è‰²å’Œèƒ½åŠ›ï¼‰
            system_prompt="""You are a helpful AI assistant specialized in solving complex tasks.
You have access to various tools including web search, code execution, and file analysis.
When given a task, break it down into steps and use available tools systematically.
Always provide your final answer in <answer>...</answer> tags.""",
            
            # MCP å·¥å…·é…ç½®
            mcp_config=gaia_env_config,
            mcp_servers=gaia_env_servers,
        )
```

### é…ç½® agent.yaml

åœ¨ `train/examples/train_gaia_with_aworld_verl/agent.yaml` ä¸­æ³¨å†Œä½ çš„ AgentLoopï¼š

```yaml
- name: gaia_agent
  _target_: train.examples.train_gaia_with_aworld_verl.custom_agent_loop.GaiaAgentLoop
```

### é«˜çº§åœºæ™¯

#### å¤š Agent ç³»ç»Ÿ

```python
from aworld.swarms.swarm import Swarm

class MultiAgentLoop(AworldAgentLoop):
    def build_agents(self):
        config, servers = get_agent_tool_env_and_servers()
        
        # åˆ›å»ºä¸“ä¸šåŒ– Agent
        researcher = Agent(
            conf=AgentConfig(...),
            name="researcher",
            system_prompt="You are a research specialist...",
            mcp_servers=["googlesearch-server", "wiki-server"]
        )
        
        coder = Agent(
            conf=AgentConfig(...),
            name="coder",
            system_prompt="You are a coding expert...",
            mcp_servers=["e2b-code-server", "terminal-server"]
        )
        
        # æ„å»º Swarm
        return Swarm(
            agents=[researcher, coder],
            coordinator=researcher  # ä¸»åè°ƒ Agent
        )
```

---

## å‡†å¤‡è®­ç»ƒ

### 1. å‡†å¤‡æ•°æ®é›†

è¿è¡Œæ•°æ®é›†ç”Ÿæˆè„šæœ¬ï¼Œå°† GAIA æ•°æ®è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼ï¼š

```bash
cd ~/AWorld/train/examples/train_gaia_with_aworld_verl/gaia_datasets

python create_dataset.py \
  --dataset_path ~/AWorld/env/gaia-mcp-server/docker/gaia_dataset \
  --output_dir ~/datasets \
  --train_size 300 \
  --test_size 100
```

è¿™å°†ç”Ÿæˆï¼š
- `~/datasets/train.parquet`ï¼š300 æ¡è®­ç»ƒæ ·æœ¬
- `~/datasets/test.parquet`ï¼š100 æ¡æµ‹è¯•æ ·æœ¬

æ•°æ®æ ¼å¼ï¼ˆParquetï¼‰ï¼š

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `prompt` | List[Dict] | æ ¼å¼åŒ–çš„èŠå¤©æ¶ˆæ¯ `[{"role": "user", "content": "..."}]` |
| `data_source` | str | æ•°æ®æ¥æºæ ‡è¯† `"gaia"` |
| `ability` | str | èƒ½åŠ›ç±»åˆ« `"agi"` |
| `reward_model` | Dict | å¥–åŠ±é…ç½® `{"style": "GAIA", "ground_truth": "..."}` |
| `extra_info` | Dict | é¢å¤–å…ƒæ•°æ®ï¼ˆtask_id, level ç­‰ï¼‰ |
| `agent_name` | str | ç›®æ ‡ Agent åç§° |

### 2. é…ç½®å¥–åŠ±å‡½æ•°

åœ¨ `train/examples/train_gaia_with_aworld_verl/metrics/gaia_reward_function.py` ä¸­å®šä¹‰å¥–åŠ±é€»è¾‘ï¼š

```python
import re
from aworld.logs.util import logger

def gaia_reward_func(data_source, solution_str, ground_truth, extra_info=None):
    """
    GAIA ä»»åŠ¡çš„å¥–åŠ±å‡½æ•°
    
    Args:
        data_source: æ•°æ®æ¥æºæ ‡è¯†
        solution_str: Agent ç”Ÿæˆçš„å®Œæ•´è§£ç­”
        ground_truth: æ ‡å‡†ç­”æ¡ˆ
        extra_info: é¢å¤–ä¿¡æ¯ï¼ˆå¦‚ task_id, levelï¼‰
    
    Returns:
        float: å¥–åŠ±å€¼ï¼ˆ0.0 æˆ– 1.0ï¼‰
    """
    # ä» solution_str ä¸­æå– <answer>...</answer> æ ‡ç­¾å†…å®¹
    pattern = r'<answer>(.*?)</answer>'
    match = re.search(pattern, solution_str, re.DOTALL | re.MULTILINE)
    
    if not match:
        logger.warning("No answer tag found in solution")
        return 0.0
    
    answer = match.group(1).strip()
    logger.info(f"Extracted answer: {answer}, Ground truth: {ground_truth}")
    
    # ä½¿ç”¨ GAIA æ ‡å‡†è¯„åˆ†å™¨ï¼ˆæ”¯æŒæ•°å­—ã€åˆ—è¡¨ã€å­—ç¬¦ä¸²ï¼‰
    if question_scorer(answer, ground_truth):
        return 1.0
    else:
        return 0.0

def question_scorer(model_answer: str, ground_truth: str) -> bool:
    """GAIA æ ‡å‡†è¯„åˆ†é€»è¾‘ï¼ˆçœç•¥è¯¦ç»†å®ç°ï¼‰"""
    # æ”¯æŒæ•°å­—æ¯”è¾ƒã€åˆ—è¡¨æ¯”è¾ƒã€å­—ç¬¦ä¸²å½’ä¸€åŒ–æ¯”è¾ƒ
    # è¯¦è§å®Œæ•´ä»£ç 
    ...
```

### 3. é…ç½®è®­ç»ƒè„šæœ¬

ç¼–è¾‘ `run.sh`ï¼Œé…ç½®å…³é”®å‚æ•°ï¼š

```bash
#!/usr/bin/env bash
set -xeuo pipefail

# ============ é›†ç¾¤æ‹“æ‰‘ ============
export GPUS_PER_NODE=${GPUS_PER_NODE:-8}
export NNODES=${NNODES:-1}

# ============ æ¨¡å‹å’Œæ•°æ® ============
model_path=${model_path:-Qwen/Qwen3-4B-Thinking-2507}
train_files=$DATA_ROOT/datasets/train.parquet
test_files=$DATA_ROOT/datasets/test.parquet

# ============ è‡ªå®šä¹‰é…ç½® ============
path_to_train="/root/AWorld/train"
agent_loop_config_path=${path_to_train}/examples/train_gaia_with_aworld_verl/agent.yaml
reward_fn_file_path=${path_to_train}/examples/train_gaia_with_aworld_verl/metrics/gaia_reward_function.py
reward_fn_name=gaia_reward_func

# ============ è®­ç»ƒè¶…å‚æ•° ============
# PPO ç®—æ³•é…ç½®
adv_estimator=grpo              # ä½¿ç”¨ Group Relative Policy Optimization
clip_ratio_low=0.2              # PPO clip ä¸‹ç•Œ
clip_ratio_high=0.28            # PPO clip ä¸Šç•Œ
actor_lr=1e-6                   # Actor å­¦ä¹ ç‡

# é•¿ä¸Šä¸‹æ–‡é…ç½®ï¼ˆAWorld æœ€æ–°ä¼˜åŒ–ï¼‰
max_turns=32                    # æœ€å¤§äº¤äº’è½®æ•°ï¼ˆä» 8 æå‡åˆ° 32ï¼‰
max_prompt_length=4096          # æç¤ºæœ€å¤§é•¿åº¦ï¼ˆä» 1024 æå‡åˆ° 4096ï¼‰
max_response_length=4096        # å“åº”æœ€å¤§é•¿åº¦ï¼ˆä» 2048 æå‡åˆ° 4096ï¼‰

# æ‰¹æ¬¡é…ç½®
train_batch_size=32             # è®­ç»ƒæ‰¹æ¬¡å¤§å°ï¼ˆä» 1 æå‡åˆ° 32ï¼‰
ppo_mini_batch_size=8           # PPO mini-batch å¤§å°ï¼ˆ4 ä¸ªæ¢¯åº¦æ›´æ–°ï¼‰
n_resp_per_prompt=16            # æ¯ä¸ªæç¤ºé‡‡æ · 16 ä¸ªå“åº”ï¼ˆä» 1 æå‡ï¼‰
n_resp_per_prompt_val=16        # éªŒè¯æ—¶é‡‡æ ·æ•°

# ============ MCP Server ============
export MCP_SERVER_URL=${MCP_SERVER_URL:-http://localhost:8080/mcp}

# ============ æ€§èƒ½ä¼˜åŒ– ============
export VLLM_USE_V1=1                      # ä½¿ç”¨ vLLM v1 å¼•æ“
export VLLM_ATTENTION_BACKEND=FLASH_ATTN  # FlashAttention-2
infer_tp=1                                # Tensor Parallel å¤§å°
train_sp=1                                # Sequence Parallel å¤§å°
offload=true                              # å‚æ•°å¸è½½åˆ° CPU

# ============ VeRL è®­ç»ƒå‘½ä»¤ ============
python3 -m verl.trainer.main_ppo \
    algorithm.adv_estimator=$adv_estimator \
    data.train_files="['$train_files']" \
    data.val_files="['$test_files']" \
    data.return_raw_chat=true \
    data.train_batch_size=$train_batch_size \
    data.max_prompt_length=$max_prompt_length \
    data.max_response_length=$max_response_length \
    actor_rollout_ref.model.path="$model_path" \
    actor_rollout_ref.rollout.multi_turn.max_user_turns=$max_turns \
    actor_rollout_ref.rollout.multi_turn.max_assistant_turns=$max_turns \
    actor_rollout_ref.rollout.max_model_len=131072 \
    actor_rollout_ref.rollout.max_num_batched_tokens=131072 \
    actor_rollout_ref.rollout.gpu_memory_utilization=0.9 \
    actor_rollout_ref.rollout.agent.agent_loop_config_path=$agent_loop_config_path \
    custom_reward_function.path="${reward_fn_file_path}" \
    custom_reward_function.name="${reward_fn_name}" \
    trainer.logger=['console','wandb'] \
    trainer.experiment_name=aworld_train_qwen3_4b \
    trainer.save_freq=5 \
    trainer.test_freq=5 \
    +trainer.num_steps=300
```

---

## å¯åŠ¨è®­ç»ƒ

### å•æœºè®­ç»ƒ

```bash
cd ~/AWorld/train/examples/train_gaia_with_aworld_verl

# å¯åŠ¨è®­ç»ƒï¼ˆ8å¡ GPUï¼‰
export DATA_ROOT=~/datasets
export GPUS_PER_NODE=8
bash run.sh
```

### å¤šæœºè®­ç»ƒï¼ˆSlurmï¼‰

```bash
# æäº¤ Slurm ä½œä¸šï¼ˆ2 èŠ‚ç‚¹ï¼Œæ¯èŠ‚ç‚¹ 8 å¡ï¼‰
sbatch <<EOF
#!/bin/bash
#SBATCH --job-name=aworld-train
#SBATCH --nodes=2
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=8
#SBATCH --time=48:00:00

export DATA_ROOT=/path/to/datasets
export NNODES=2
export GPUS_PER_NODE=8

srun bash run.sh
EOF
```

### è®­ç»ƒç›‘æ§

è®­ç»ƒè¿‡ç¨‹æ”¯æŒå¤šç§æ—¥å¿—åç«¯ï¼š

```bash
# 1. æ§åˆ¶å°è¾“å‡º
# å®æ—¶æŸ¥çœ‹è®­ç»ƒæŒ‡æ ‡ï¼ˆloss, reward, KL divergence ç­‰ï¼‰

# 2. WandB å¯è§†åŒ–ï¼ˆæ¨èï¼‰
# è®¿é—® https://wandb.ai/<your-project>/aworld_train_qwen3_4b

# 3. TensorBoard
tensorboard --logdir ~/datasets/checkpoint/aworld_train_qwen3_4b
```

å…³é”®ç›‘æ§æŒ‡æ ‡ï¼š

| æŒ‡æ ‡ | è¯´æ˜ | ç›®æ ‡å€¼ |
|------|------|--------|
| `reward/mean` | å¹³å‡å¥–åŠ± | é€æ­¥ä¸Šå‡è‡³ 0.3+ |
| `reward/max` | æœ€å¤§å¥–åŠ± | è¾¾åˆ° 1.0 |
| `actor/loss` | Actor æŸå¤± | ç¨³å®šä¸‹é™ |
| `rollout/response_length` | å“åº”é•¿åº¦ | æ ¹æ®ä»»åŠ¡è°ƒæ•´ |
| `rollout/num_turns` | å¹³å‡è½®æ•° | é«˜æ•ˆåˆ©ç”¨å·¥å…·ï¼ˆ5-15 è½®ï¼‰ |

---

## æœ€æ–°ä¼˜åŒ–

åŸºäºæœ€æ–°ä»£ç ä¿®æ”¹ï¼ˆcommit `a52d61d6`ï¼‰ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä»¥ä¸‹å…³é”®ä¼˜åŒ–ï¼š

### 1. é•¿ä¸Šä¸‹æ–‡æ”¯æŒï¼ˆverl_provider.pyï¼‰

```python
# æ–°å¢ max_model_len å‚æ•°åŠ¨æ€é…ç½®
self.max_model_len = params.get("max_model_len", 24576)
```

**å½±å“**ï¼šæ”¯æŒæœ€é•¿ 131K tokens çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œå¤„ç†å¤æ‚å¤šè½®å¯¹è¯å’Œå¤§è§„æ¨¡å·¥å…·è°ƒç”¨å†å²ã€‚

### 2. æ•°æ®æ ¼å¼ä¼˜åŒ–ï¼ˆcreate_dataset.pyï¼‰

```python
# æç¤ºæ ¼å¼åŒ–ä¸ºèŠå¤©æ¶ˆæ¯åˆ—è¡¨ï¼ˆé€‚é… VeRL return_raw_chat æ¨¡å¼ï¼‰
rl_dataset["prompt"].append([{"role": "user", "content": data["Question"]}])
```

**å½±å“**ï¼šä¸ VeRL çš„èŠå¤©æ¨¡æ¿ç³»ç»Ÿæ— ç¼å¯¹æ¥ï¼Œé¿å…æ ¼å¼è½¬æ¢å¼€é”€ã€‚

### 3. è¶…å‚æ•°è°ƒä¼˜ï¼ˆrun.shï¼‰

| å‚æ•° | æ—§å€¼ | æ–°å€¼ | æå‡ |
|------|------|------|------|
| `max_turns` | 8 | 32 | 4x äº¤äº’æ·±åº¦ |
| `max_prompt_length` | 1024 | 4096 | 4x è¾“å…¥å®¹é‡ |
| `max_response_length` | 2048 | 4096 | 2x è¾“å‡ºå®¹é‡ |
| `train_batch_size` | 1 | 32 | 32x è®­ç»ƒæ•ˆç‡ |
| `n_resp_per_prompt` | 1 | 16 | 16x æ ·æœ¬å¤šæ ·æ€§ |

**å½±å“**ï¼š
- **æ›´æ·±å±‚æ¨ç†**ï¼šå…è®¸ Agent è¿›è¡Œæ›´é•¿æ—¶é—´çš„å·¥å…·é“¾è°ƒç”¨å’Œæ€è€ƒ
- **æ›´é«˜æ•ˆè®­ç»ƒ**ï¼šå¤§æ‰¹æ¬¡è®­ç»ƒåŠ é€Ÿæ”¶æ•›ï¼Œå¤šæ ·æœ¬é‡‡æ ·æå‡æ³›åŒ–èƒ½åŠ›
- **æ›´ç¨³å®šä¼˜åŒ–**ï¼š`ppo_mini_batch_size=8` å®ç° 4 æ¬¡æ¢¯åº¦æ›´æ–°ï¼Œå¹³è¡¡è®­ç»ƒç¨³å®šæ€§å’Œæ•ˆç‡

### 4. å†…å­˜ä¼˜åŒ–

```bash
# vLLM é…ç½®
actor_rollout_ref.rollout.max_model_len=131072           # æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦
actor_rollout_ref.rollout.max_num_batched_tokens=131072  # æ‰¹å¤„ç† token æ•°
actor_rollout_ref.rollout.gpu_memory_utilization=0.9     # GPU å†…å­˜åˆ©ç”¨ç‡
```

**å½±å“**ï¼šåœ¨ A100 80GB ä¸Šæ”¯æŒ 32K+ tokens çš„å¹¶å‘æ¨ç†ï¼Œå……åˆ†åˆ©ç”¨ GPU èµ„æºã€‚

### 5. æ–°å¢ Qwen3-30B-A3B è®­ç»ƒè„šæœ¬

```bash
# run_qwen3_30b_a3b.sh
infer_tp=4   # Tensor Parallelï¼ˆæ¨ç†ï¼‰
train_sp=8   # Sequence Parallelï¼ˆè®­ç»ƒï¼‰
```

**å½±å“**ï¼šæ”¯æŒæ›´å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒï¼Œåˆ©ç”¨æ¨¡å‹å¹¶è¡ŒæŠ€æœ¯çªç ´å•å¡é™åˆ¶ã€‚

---

## æ•…éšœæ’æŸ¥

### Agent è®­ç»ƒè¿‡ç¨‹è¾“å‡ºç¤ºä¾‹

#### âœ… æ­£å¸¸æ¨ç†æµç¨‹

```
(AgentLoopWorker pid=448354)   [agent] Content: Okay, let's see. So the user is asking about the population difference between the two states that have both Carl's Jr. and Hardee's fast food restaurants...
(AgentLoopWorker pid=448354)   [agent] Tool call: aworld-mcp__search_google - ID: chatcmpl-tool-94b30baa
(AgentLoopWorker pid=448354)   [agent] Tool args: {"query": "Wyoming population 2020", "num_results": 5}
(AgentLoopWorker pid=448354)   [agent] Content: ["{\"success\": true, \"message\": {\"query\": \"Wyoming population 2020\", \"results\": [{\"title\": \"Wyoming - Census Bureau Profile\", \"snippet\": \"576,851. The Total Population for Wyoming is 576,851...\"...}
```

**è¯´æ˜**ï¼šAgent æ­£ç¡®è°ƒç”¨å·¥å…·å¹¶æ¥æ”¶ç»“æœï¼Œæ¨ç†é“¾è·¯å®Œæ•´ã€‚

#### âœ… æ–‡ä»¶åˆ—è¡¨æˆåŠŸ

```
(AgentLoopWorker pid=448358)   [agent] Content: ["[FILE] 021a5339-744f-42b7-bd9b-9368b3efda7a.pdf\n[FILE] 03c577c9-4227-48a9-9b75-f8f598de14c1.mp3\n[FILE] 063800f6-8832-4856-972b-17b877612533.png\n..."]
(AgentLoopWorker pid=448358)   [agent] Content: Okay, let's try to figure out how many horror titles are overdue based on the inventory file...
```

**è¯´æ˜**ï¼šæ–‡ä»¶ç³»ç»Ÿå·¥å…·æ­£å¸¸å·¥ä½œï¼ŒAgent èƒ½å¤Ÿè®¿é—®æ•°æ®é›†æ–‡ä»¶ã€‚

---

### GAIA MCP Server è¾“å‡ºç¤ºä¾‹

#### âœ… æ­£å¸¸å¯åŠ¨è¾“å‡º

```bash
$ docker logs gaia-mcp-server-gaia-mcp-server-1 -f

Starting services...
DISPLAY=:0
2025-10-06 05:20:42,368 - __main__ - INFO - Starting MCP Server Proxy...
2025-10-06 05:20:42,370 - mcp_server_proxy.mcp_server_proxy - INFO - Loaded MCP tool schema: mcp_tool_schema=
  readweb-server:
  browser-server:
    - get_browser_capabilities
    - browser_use
  documents-csv-server:
    - extract_csv_content
    - list_supported_formats
  googlesearch-server:
    - search_google
    - get_search_capabilities
  ...
2025-10-06 05:20:42,373 - mcp_server_proxy.mcp_server_proxy - INFO - Added MCP server executor: googlesearch-server
INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)
```

**æ£€æŸ¥ç‚¹**ï¼š
- âœ… `Starting MCP Server Proxy` å‡ºç°
- âœ… 20+ å·¥å…·æœåŠ¡å™¨è¢«åŠ è½½ï¼ˆ`Added MCP server executor`ï¼‰
- âœ… Uvicorn åœ¨ 8080 ç«¯å£ç›‘å¬

#### âœ… è®­ç»ƒæ—¶æ­£å¸¸è¯·æ±‚

```
INFO:     208.64.254.164:36416 - "POST /mcp HTTP/1.1" 200 OK
2025-10-06 05:09:23,880 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
2025-10-06 05:09:27,006 - mcp.server.lowlevel.server - INFO - Processing request of type CallToolRequest
[10/06/25 05:09:27] INFO     ğŸ” Searching Google for: 'Speaker of the House that passed act...'
                    INFO     âœ… Found 5 results in 0.42s
```

**è¯´æ˜**ï¼šAgent æ­£å¸¸è°ƒç”¨ Google æœç´¢å·¥å…·ï¼Œè¯·æ±‚å“åº”å¿«é€Ÿï¼ˆ< 1sï¼‰ã€‚

---

### âŒ å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

#### 1. CSV æå–å¤±è´¥ï¼ˆç¼ºå°‘ä¾èµ–ï¼‰

```
ERROR    CSV extraction failed: Missing optional dependency 'tabulate'.
         Use pip or conda to install tabulate.
```

**åŸå› **ï¼špandas çš„ `to_markdown()` åŠŸèƒ½éœ€è¦ `tabulate` åº“ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# è¿›å…¥ MCP Server Docker å®¹å™¨
docker exec -it gaia-mcp-server-gaia-mcp-server-1 bash

# å®‰è£…ç¼ºå¤±ä¾èµ–
cd /app/mcp_servers/documents_server
source .venv/bin/activate
pip install tabulate

# é‡å¯å®¹å™¨
exit
docker restart gaia-mcp-server-gaia-mcp-server-1
```

#### 2. OpenAI API å¯†é’¥é”™è¯¯

```
WARNING  coding failed: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-or-v1***...', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}
```

**åŸå› **ï¼š`intelligence-code-server` ç­‰å·¥å…·éœ€è¦ OpenAI API å¯†é’¥ç”Ÿæˆä»£ç ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# æ–¹æ³• 1ï¼šé…ç½®çœŸå® OpenAI API Key
vim ~/AWorld/env/gaia-mcp-server/mcp_servers/.env
# æ·»åŠ ï¼šOPENAI_API_KEY=sk-your-real-key

# æ–¹æ³• 2ï¼šä½¿ç”¨ OpenRouter ç­‰å…¼å®¹æœåŠ¡
# .env ä¸­é…ç½®ï¼š
LLM_BASE_URL=https://openrouter.ai/api/v1
OPENAI_API_KEY=sk-or-v1-your-openrouter-key

# é‡å¯æœåŠ¡
cd ~/AWorld/env
bash run-local.sh
```

#### 3. Wikipedia API 429 é™æµ

```
ERROR    Wikipedia summary retrieval error:
         requests.exceptions.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
```

**åŸå› **ï¼šWikipedia API é™æµï¼ˆ429 Too Many Requestsï¼‰ï¼Œä½† Python åº“æ²¡æœ‰æ­£ç¡®å¤„ç†ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# æ–¹æ³• 1ï¼šé™ä½å¹¶å‘è¯·æ±‚ï¼ˆè°ƒæ•´è®­ç»ƒå‚æ•°ï¼‰
train_batch_size=16  # ä» 32 é™ä½åˆ° 16
n_resp_per_prompt=8  # ä» 16 é™ä½åˆ° 8

# æ–¹æ³• 2ï¼šä½¿ç”¨ä»£ç†æˆ–åˆ‡æ¢ Wikipedia é•œåƒ
# åœ¨ wiki_server/.env ä¸­é…ç½®ï¼š
WIKIPEDIA_BASE_URL=https://en.wikipedia.org/w/api.php

# æ–¹æ³• 3ï¼šæ·»åŠ è¯·æ±‚é‡è¯•é€»è¾‘ï¼ˆéœ€ä¿®æ”¹ä»£ç ï¼‰
# åœ¨ wiki_server/src/wiki.py ä¸­æ·»åŠ  exponential backoff
```

#### 4. å·¥å…·æ‰§è¡Œè¶…æ—¶

```
2025-10-06 05:21:08,548 - mcp_server_proxy.mcp_server_executor - INFO - Starting tool server browser-server...
[10 ç§’åæ— å“åº”]
```

**åŸå› **ï¼šæµè§ˆå™¨å·¥å…·ï¼ˆPlaywrightï¼‰å¯åŠ¨æ…¢æˆ–èµ„æºä¸è¶³ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# å¢åŠ è¶…æ—¶é…ç½®
vim ~/AWorld/env/gaia-mcp-server/mcp_servers/.env
# æ·»åŠ ï¼š
TOOL_EXECUTION_TIMEOUT=120  # ä»é»˜è®¤ 60s å¢åŠ åˆ° 120s

# é¢„çƒ­æµè§ˆå™¨ç¯å¢ƒ
docker exec -it gaia-mcp-server-gaia-mcp-server-1 bash
cd /app/mcp_servers/browser_server
uv run python -c "from playwright.sync_api import sync_playwright; sync_playwright().start()"
```

#### 5. vLLM OOMï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰

```
RuntimeError: CUDA out of memory. Tried to allocate 20.00 GiB (GPU 0; 79.35 GiB total capacity; 75.12 GiB already allocated; 2.31 GiB free; 78.90 GiB reserved in total by PyTorch)
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

```bash
# æ–¹æ³• 1ï¼šé™ä½æ‰¹æ¬¡å¤§å°
train_batch_size=16             # ä» 32 é™ä½
ppo_mini_batch_size=4          # ä» 8 é™ä½

# æ–¹æ³• 2ï¼šé™ä½ GPU å†…å­˜åˆ©ç”¨ç‡
actor_rollout_ref.rollout.gpu_memory_utilization=0.75  # ä» 0.9 é™ä½

# æ–¹æ³• 3ï¼šå¯ç”¨ CPU offload
actor_rollout_ref.actor.fsdp_config.param_offload=true
actor_rollout_ref.actor.fsdp_config.optimizer_offload=true

# æ–¹æ³• 4ï¼šä½¿ç”¨æ›´å¤§çš„ Tensor Parallel
infer_tp=4  # ä» 1 å¢åŠ åˆ° 4ï¼ˆéœ€è¦ 4 å¡ï¼‰
```

---

### è°ƒè¯•æŠ€å·§

#### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—

```bash
# VeRL è®­ç»ƒæ—¥å¿—
export RAY_LOGGING_LEVEL=DEBUG
export HYDRA_FULL_ERROR=1

# MCP Server æ—¥å¿—
docker logs -f gaia-mcp-server-gaia-mcp-server-1 --tail 100

# vLLM æ¨ç†æ—¥å¿—
export VLLM_LOGGING_LEVEL=DEBUG
```

#### 2. å•æ­¥è°ƒè¯• Agent

```python
# test_agent_debug.py
from train.examples.train_gaia_with_aworld_verl.custom_agent_loop import GaiaAgentLoop

# åˆ›å»º AgentLoopï¼ˆä¸å¯åŠ¨è®­ç»ƒï¼‰
loop = GaiaAgentLoop()
agent = loop.build_agents()

# æµ‹è¯•å•ä¸ªé—®é¢˜
response = agent.chat("What is the capital of France?")
print(response)
```

#### 3. æ£€æŸ¥å·¥å…·å¯ç”¨æ€§

```bash
# æµ‹è¯• MCP Server å¥åº·çŠ¶æ€
curl http://localhost:8080/health

# åˆ—å‡ºæ‰€æœ‰å·¥å…·
curl -X POST http://localhost:8080/mcp \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc": "2.0", "method": "tools/list", "params": {}, "id": 1}'
```

---

## æ€§èƒ½åŸºå‡†

### GAIA æµ‹è¯•é›†ç»“æœï¼ˆæ ¹æ®è®ºæ–‡ï¼‰

| æ¨¡å‹ | Pass@1 | æ•°æ®æ”¶é›†åŠ é€Ÿ | è®­ç»ƒæ—¶é—´ |
|------|--------|-------------|---------|
| GPT-4o (Baseline) | 27.91% | - | - |
| DeepSeek-V3 | 31.89% | - | - |
| **Qwen3-32B-AWorld** | **32.23%** | **14.6x** | 48h (8x A100) |

**å…³é”®å‘ç°**ï¼š
- é€šè¿‡"ä»å®è·µä¸­å­¦ä¹ "èŒƒå¼ï¼Œ32B å‚æ•°æ¨¡å‹è¶…è¶Šäº† GPT-4o å’Œ DeepSeek-V3
- åˆ†å¸ƒå¼ç»éªŒç”Ÿæˆå°†æ•°æ®æ”¶é›†æ—¶é—´ä» 7 å¤©ç¼©çŸ­è‡³ 12 å°æ—¶
- ç«¯åˆ°ç«¯è®­ç»ƒï¼ˆSFT + PPOï¼‰åœ¨ GAIA éªŒè¯é›†ä¸Šæå‡ 15+ ä¸ªç™¾åˆ†ç‚¹

### ç¡¬ä»¶æ€§èƒ½

| é…ç½® | Throughput | GPU åˆ©ç”¨ç‡ | å†…å­˜å ç”¨ |
|------|------------|-----------|---------|
| 1x A100 80GB (TP=1) | 120 tokens/s | 85% | 72GB |
| 4x A100 80GB (TP=4) | 450 tokens/s | 92% | 68GB/GPU |
| 8x A100 80GB (FSDP+TP) | 850 tokens/s | 95% | 70GB/GPU |

**ä¼˜åŒ–å»ºè®®**ï¼š
- **å°æ¨¡å‹ï¼ˆ< 8Bï¼‰**ï¼šå•å¡è®­ç»ƒï¼Œ`infer_tp=1`, `train_sp=1`
- **ä¸­ç­‰æ¨¡å‹ï¼ˆ8-30Bï¼‰**ï¼šä½¿ç”¨ TP=4 åŠ é€Ÿæ¨ç†ï¼Œ`infer_tp=4`
- **å¤§æ¨¡å‹ï¼ˆ> 30Bï¼‰**ï¼šç»„åˆä½¿ç”¨ TP å’Œ SPï¼Œ`infer_tp=4, train_sp=8`

---

## è¿›é˜¶ä¸»é¢˜

### è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°

é™¤äº† GAIA çš„äºŒå…ƒå¥–åŠ±ï¼Œä½ è¿˜å¯ä»¥å®ç°æ›´å¤æ‚çš„å¥–åŠ±å¡‘å½¢ï¼š

```python
def dense_reward_func(data_source, solution_str, ground_truth, extra_info=None):
    """å¯†é›†å¥–åŠ±å‡½æ•°ï¼ˆè€ƒè™‘ä¸­é—´æ­¥éª¤ï¼‰"""
    reward = 0.0
    
    # 1. å·¥å…·ä½¿ç”¨å¥–åŠ±ï¼ˆé¼“åŠ±æ¢ç´¢ï¼‰
    num_tool_calls = solution_str.count("Tool call:")
    reward += min(num_tool_calls * 0.1, 0.5)  # æœ€å¤š 0.5 åˆ†
    
    # 2. æ¨ç†è´¨é‡å¥–åŠ±ï¼ˆåŸºäº CoTï¼‰
    if "<think>" in solution_str and "</think>" in solution_str:
        reward += 0.2  # æœ‰æ€è€ƒè¿‡ç¨‹
    
    # 3. æœ€ç»ˆç­”æ¡ˆå¥–åŠ±ï¼ˆä¸»è¦åˆ†æ•°ï¼‰
    if question_scorer(extract_answer(solution_str), ground_truth):
        reward += 1.0
    
    # 4. æ•ˆç‡æƒ©ç½šï¼ˆé¿å…è¿‡åº¦å·¥å…·è°ƒç”¨ï¼‰
    if num_tool_calls > 15:
        reward -= 0.2
    
    return reward
```

### å¤šä»»åŠ¡è®­ç»ƒ

```python
# gaia_datasets/create_multitask_dataset.py
def create_multitask_dataset():
    datasets = []
    
    # ä»»åŠ¡ 1ï¼šGAIA
    gaia_ds = load_gaia_dataset(...)
    gaia_ds['task_type'] = 'gaia'
    datasets.append(gaia_ds)
    
    # ä»»åŠ¡ 2ï¼šCode Execution
    code_ds = load_code_dataset(...)
    code_ds['task_type'] = 'code'
    datasets.append(code_ds)
    
    # ä»»åŠ¡ 3ï¼šWeb Navigation
    web_ds = load_webarena_dataset(...)
    web_ds['task_type'] = 'web'
    datasets.append(web_ds)
    
    # æ··åˆé‡‡æ ·
    return pd.concat(datasets).sample(frac=1.0)
```

---

## å¼•ç”¨

å¦‚æœä½ åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº† AWorld Trainï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```bibtex
@article{yu2025aworld,
  title={AWorld: Orchestrating the Training Recipe for Agentic AI},
  author={Yu, Chengyue and Lu, Siyuan and Zhuang, Chenyi and Wang, Dong and others},
  journal={arXiv preprint arXiv:2508.20404},
  year={2025}
}
```

---

## ç¤¾åŒºä¸æ”¯æŒ

- **GitHub Issues**: [https://github.com/inclusionAI/AWorld/issues](https://github.com/inclusionAI/AWorld/issues)
- **Discord**: [https://discord.gg/aworld](https://discord.gg/aworld)
- **è®ºæ–‡**: [https://arxiv.org/abs/2508.20404](https://arxiv.org/abs/2508.20404)
- **å®˜æ–¹æ–‡æ¡£**: [https://inclusionai.github.io/AWorld/](https://inclusionai.github.io/AWorld/)

---

<div align="center">

**AWorld Train** â€” è®©ä½ çš„ Agent ä»å®è·µä¸­å­¦ä¹ 

Made with â¤ï¸ by [Inclusion AI](https://github.com/inclusionAI)

</div>

[license-image]: https://img.shields.io/badge/License-MIT-yellow.svg
[license-url]: https://opensource.org/licenses/MIT